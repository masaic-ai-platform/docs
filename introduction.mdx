---
title: 'Introduction'
description: 'Unlock enterprise-grade AI capabilities through a single, powerful API'
---

# Drive Business Impact with OpenResponses

## Deliver Results Faster, at Lower Cost
OpenResponses helps businesses streamline AI adoption without sacrificing security or compliance. By self-hosting the API, organizations retain full control over data and minimize risk—while still empowering teams to leverage the latest AI breakthroughs.
- **Enterprise-Grade Data Privacy**: Keep sensitive information fully under your control—no external cloud dependencies.
- **All-in-One Platform**: Eliminate the hassle of juggling multiple disjointed services. Access web search, GitHub, and context retrieval from a single API.
- **Instant ROI**: Shorten time-to-value with prebuilt integrations and automated tracing for auditing performance and usage.
- **Compliance Assured**: Meet regulatory requirements and internal security policies with a solution you manage on your own servers.

# Empower AI Agent Builders

## Focus on Innovation, Not Infrastructure
OpenResponses supercharges your ability to build AI-driven agents and apps by providing the essential tools out of the box.
- **Automatic Data Retrieval (RAG)**: Enhance chatbot or agent responses with real-time access to external and internal data.
- **Integrated Tooling**: Leverage built-in web search, GitHub access, and more—no tedious setup required.
- **Unified API Interface**: Add advanced AI features to your apps simply by calling an OpenAI-compatible endpoint.
- **Real-Time Monitoring**: Gain immediate insights into performance, usage patterns, and debug logs through automated tracing.

# Get Started in Minutes

## Launch with a Single Docker Command
Whether you're an experienced dev or just exploring AI, OpenResponses makes it dead simple to spin up your own AI environment.

```bash
docker run -p 8080:8080 masaicai/open-responses:latest
```

## Seamless Integration
If you already use the OpenAI SDK, just point your API calls to OpenResponses. Minimal code changes—maximum productivity.

```python
from openai import OpenAI
import os

openai_client = OpenAI(
    base_url="http://localhost:8080/v1", 
    api_key=os.getenv("OPENAI_API_KEY"), 
    default_headers={'x-model-provider': 'openai'}
)

response = openai_client.responses.create(
    model="gpt-4o-mini",
    input="Tell me a joke"
)
```

### Using with OpenAI Agent SDK
```python
from openai import AsyncOpenAI
from openai.agents import Agent, OpenAIResponsesModel
import os

client = AsyncOpenAI(
    base_url="http://localhost:8080/v1", 
    api_key=os.getenv("OPENAI_API_KEY"), 
    default_headers={'x-model-provider': 'openai'}
)

agent = Agent(
    name="Assistant",
    instructions="You are a humorous poet who can write funny poems of 4 lines.",
    model=OpenAIResponsesModel(model="gpt-4o-mini", openai_client=client)
)
```

### Using with cURL
```bash
curl --location 'http://localhost:8080/v1/responses' \
--header 'Content-Type: application/json' \
--header 'Authorization: Bearer OPENAI_API_KEY' \
--header 'x-model-provider: openai' \
--data '{
    "model": "gpt-4o",
    "stream": false,
    "input": [
        {
            "role": "user",
            "content": "Tell me a joke"
        }
    ]
}'
```

## Build and Iterate Faster
Focus on creating AI-driven experiences, not wrestling with infrastructure. OpenResponses gives you a production-ready, enterprise-capable AI toolkit from day one.
